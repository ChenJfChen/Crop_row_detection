{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import time\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to do color based segmentation\n",
    "def combined (img):\n",
    "    #b, g, r = cv2.split(img)\n",
    "    b = img[:, :, 0]\n",
    "    g = img[:, :, 1]\n",
    "    r = img[:, :, 2]\n",
    "    #r_max = g_max = b_max = 255\n",
    "    r_max = np.amax(r)\n",
    "    g_max = np.amax(g)\n",
    "    b_max = np.amax(b)\n",
    "    #print (r)\n",
    "    #cv2.imshow(\"red chaneel\",b)\n",
    "\n",
    "    red_norm = r/r_max\n",
    "    green_norm = g/g_max\n",
    "    blue_norm = b/b_max\n",
    "\n",
    "   # print(red_norm.shape)\n",
    "\n",
    "    norm = red_norm + blue_norm + green_norm\n",
    "\n",
    "\n",
    "    small_num = 0.0001\n",
    "    r = red_norm/(norm+small_num)\n",
    "    g = green_norm/(norm+small_num)\n",
    "    b = blue_norm/(norm+small_num)\n",
    "\n",
    "    #print('normalized r g b values: %d %d %d' %(r, g, b))\n",
    "\n",
    "    ExG = 2*g - r - b #excess green\n",
    "\n",
    "    #ExGR = ExG -1.4*r - g #excess green minus red\n",
    "\n",
    "    #CIVE = 0.441*r - 0.811*g + 0.385*b + 18.78745 #color index of vegetation extraction\n",
    "\n",
    "    #redistribute the weights without VEG\n",
    "    #w_ExG = 0.28\n",
    "    #w_ExGR = 0.34\n",
    "    #w_CIVE = 0.38\n",
    "\n",
    "    #combined = w_ExG * ExG + w_ExGR * ExGR + w_CIVE * CIVE\n",
    "\n",
    "    return ExG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create animation\n",
    "fig = plt.figure()\n",
    "# ims = []\n",
    "\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\khan1\\jupyter_test_code\\2fps_crop_row.avi')\n",
    "\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "#Frames per second using video.get(cv2.CAP_PROP_FPS) : 60.0\n",
    "\n",
    "fps = 2\n",
    "title = 'normal speed video'\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "#original video size\n",
    "height = 1346  #height = frame.shape[0]\n",
    "width = 1994   #width = frame.shape[1]\n",
    "\n",
    "#resized video size for before cropping\n",
    "new_height = 972 \n",
    "new_width = 1444\n",
    "dim = (new_width, new_height)\n",
    "\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame_counter += 1\n",
    "    print(\"frame counter: \", frame_counter)\n",
    "    \n",
    "    #resized_frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "#     height = frame.shape[0]\n",
    "#     width = frame.shape[1]\n",
    "#     print(\"Height:\",height,\"width:\",width)\n",
    "\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #crop_img = resized_frame[int(height / 5):int(height / 2 - 100), int(width / 3 - 100):int(300+(width / 3))]\n",
    "    crop_img = frame[int(height / 2 - 300):int(height / 2 + 100), int(width / 2 - 300):int(300 + (width / 2))]\n",
    "    \n",
    "    img = crop_img\n",
    "    \n",
    "    cropheight = img.shape[0]\n",
    "    cropwidth = img.shape[1]\n",
    "\n",
    "    max_value = np.max(combined(img))\n",
    "    min_value = np.min(combined(img))\n",
    "\n",
    "    ###mapped combined image value (which is mostly negative) to 0-255\n",
    "    new_min = 0\n",
    "    new_max = 255\n",
    "    old_range = max_value - min_value\n",
    "    new_range = new_max - new_min\n",
    "    lin_map = (((combined(img).astype(np.float64) - min_value) * new_range) / old_range) + new_min\n",
    "    image_map = lin_map.astype(np.uint8)\n",
    "    ###OTSU threshold\n",
    "    thresh_val,thresh_img = cv2.threshold(image_map,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    #print(thresh_img)\n",
    "    ###Morphology Opening-Closing to delete small weed segments\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh_img, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    ### all the white pixel coordinates in segemented image after noise clean\n",
    "    indices = np.where(closing == [255])\n",
    "    coordinates = list(zip(indices[0], indices[1]))\n",
    "    \n",
    "    ###convert list to array\n",
    "    ###then flip the data from x-y format to y-x format for clsuter fit\n",
    "    data = np.array(coordinates)\n",
    "    y_x_data = np.flip(data)\n",
    "    #print(y_x_data.shape)\n",
    "    \n",
    "    ##### cluster size for Veera video image ####\n",
    "    cluster_size = 1000 \n",
    "    \n",
    "    \n",
    "    ###Fit data to HDBscan\n",
    "    ### min_cluster_size=100, has direct correlation with crop growth stage, type of crop\n",
    "    ### NEED user input\n",
    "    clusters = hdbscan.HDBSCAN(min_cluster_size=cluster_size).fit(y_x_data)\n",
    "    labels = clusters.labels_\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    #print(\"clusters:\", n_clusters)\n",
    "    #good_points = clusters.exemplars_\n",
    "\n",
    "    ###subtract outliers from original cluster data\n",
    "    subtract_data = y_x_data\n",
    "    \n",
    "    \"\"\"No iterative or only counting good points Steps are not added yet (from row_detect_all_v2).\"\"\"\n",
    "    \n",
    "    print(\"clusters:\", n_clusters)\n",
    "    #print(subtract_data.shape)\n",
    "\n",
    "    ###convert list to array\n",
    "    subtract_data = np.array(subtract_data)\n",
    "\n",
    "    Ydata = subtract_data.T[0] #we plot this on x-axis\n",
    "    Xdata = subtract_data.T[1] #we plot this on y_axis\n",
    "\n",
    "    y_center = []\n",
    "    x_center = []\n",
    "\n",
    "    ### calculate center for each clusters ###\n",
    "    for i in range(0,n_clusters):\n",
    "    \n",
    "        y_center.append(int(np.mean(np.array(Ydata[labels == i])))) #distance from (0,0) along x-axis\n",
    "        x_center.append(int(np.mean(np.array(Xdata[labels == i])))) #distance from (0,0) along y-axis\n",
    "    \n",
    "    \n",
    "#         plt.scatter(np.array(Ydata[labels == i]), np.array(Xdata[labels == i])) \n",
    "#         plt.plot(y_center[i],x_center[i], \"kv\",markersize=12)\n",
    "#         plt.text(y_center[i] + 5,x_center[i], s = i+1, fontsize =10)\n",
    "#         #print(\"cluster \",i+1,\"center \", y_center[i])\n",
    "\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.show()\n",
    "    \n",
    "    # change this value according to  crop_roi size\n",
    "    cluster_distance_threshold = 100  #this value can be updated based on user input or training data\n",
    "\n",
    "    center_distance = 0\n",
    "\n",
    "    ### calculate dynamic threshold\n",
    "    center_sort = np.sort(y_center)\n",
    "\n",
    "\n",
    "    percentage = 0.3 #bigger number means small distance constraint\n",
    "\n",
    "    ###initialize with big numbers so that don't delete clusters (next cell) when don't meet following condition \n",
    "    keep = 10\n",
    "    delete = 10\n",
    "\n",
    "    ### currently the following loop works for only one outlier removal ####\n",
    "    ### should apply it for multiple  outlier cluster removal ####\n",
    "\n",
    "    deleted_cluster = []\n",
    "\n",
    "    for i in range(0,n_clusters-1):\n",
    "        for j in range(i+1,n_clusters):\n",
    "        \n",
    "            #print(\"i \",i,\"j \", j)\n",
    "        \n",
    "            cluster_distance =  np.abs(y_center[i] - y_center[j])\n",
    "            #print(\"cluster \",i+1,\"and\",j+1,\"distance \",cluster_distance)\n",
    "        \n",
    "            if (cluster_distance < (cluster_distance_threshold - percentage * cluster_distance_threshold)):\n",
    "                #print (\"Cluster trouble\",i+1,\"and\",j+1)\n",
    "            \n",
    "                ### Decide which cluster to keep based on shape and size ###\n",
    "                ### Keep : Higher number of points, higher vertical distance ###\n",
    "                ### Higher number of points may also indicate weeds, maybe just keep higher vertical height ###\n",
    "            \n",
    "                #get number of data points in cluster\n",
    "                cluster_i_points = Xdata[labels == i].shape[0]\n",
    "                cluster_j_points = Xdata[labels == j].shape[0]\n",
    "            \n",
    "                #get height of cluster\n",
    "                cluster_i_height = np.abs(max(Xdata[labels == i]) - min(Xdata[labels == i]))\n",
    "                cluster_j_height = np.abs(max(Xdata[labels == j]) - min(Xdata[labels == j]))\n",
    "            \n",
    "                if ((cluster_i_height >= cluster_j_height) & (cluster_i_points >= cluster_j_points)):\n",
    "                \n",
    "                    keep = i\n",
    "                    delete = j\n",
    "            \n",
    "                else:\n",
    "                \n",
    "                    keep = j\n",
    "                    delete = i\n",
    "                \n",
    "                #print(\"keep\",keep+1)\n",
    "                #print(\"delete\",delete+1)\n",
    "                deleted_cluster.append(delete)\n",
    "                \n",
    "#     for i in range(0,n_clusters):\n",
    "\n",
    "#         if (any(i == item for item in deleted_cluster)):\n",
    "#         #if (i == delete):\n",
    "#             pass\n",
    "\n",
    "#         else:\n",
    "#             plt.scatter(np.array(Ydata[labels == i]), np.array(Xdata[labels == i]))\n",
    "        \n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.show()\n",
    "    \n",
    "    #### Fit line over clusters ####\n",
    "\n",
    "    straight = 1\n",
    "    curve = 2\n",
    "    \n",
    "    ransac = linear_model.RANSACRegressor()\n",
    "    #### For Veera video image ###\n",
    "    vertical_ROI_height = 400\n",
    "\n",
    "    #print(\"number of clusters: \", n_clusters)\n",
    "    #print(\"deleted clusters: \", len(deleted_cluster))\n",
    "    \n",
    "    total_points = 1000\n",
    "    \n",
    "    color = ['red', 'blue', 'cyan', 'magenta', 'yellow','black','green','red', 'blue', 'cyan']\n",
    "    \n",
    "    ## Only plot lines if number of correct cluser in ROI are 3 or 4\n",
    "    if (2 < (n_clusters - len(deleted_cluster)) < 5):\n",
    "        \n",
    "        for i in range(0,n_clusters):\n",
    "\n",
    "            if (any(i == item for item in deleted_cluster)):\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                ransac.fit(Xdata[labels == i].reshape(-1,1), Ydata[labels == i].reshape(-1,1))\n",
    "                xnew_cluster = np.linspace(0, vertical_ROI_height + 373, total_points)\n",
    "                ffit_cluster = ransac.predict(xnew_cluster.reshape(-1,1))\n",
    "                #plt.plot(ffit_cluster, xnew_cluster, '-',color = color[i])\n",
    "                plt.scatter(ffit_cluster, xnew_cluster,color= color[i])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "#     plt.gca().axes.get_xaxis().set_visible(False)\n",
    "#     plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    #plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    #plt.savefig(r\"C:\\Users\\khan1\\jupyter_test_code\\line_draw_img\\{}.png\".format(frame_counter),bbox_inches='tight',pad_inches = 0)\n",
    "    plt.show()\n",
    "    \n",
    "\"\"\"Steps to create line drawn vidoe of original frame\n",
    "1. save line draw image of cropped frame on C:\\Users\\khan1\\jupyter_test_code\\line_draw_img\\{}.png\"\n",
    "2. open 'superimpose_crop_line_into_orig_frame.ipynb' and create image of line drawn on original frame\n",
    "3. create video and saved in C:\\Users\\khan1\\jupyter_test_code\\detected_crop_row_orig_frame.avi\"\"\"\n",
    "    \n",
    "#     #cv2.imshow(title,frame)\n",
    "# #     cv2.imshow(\"Cropped frame\",img)\n",
    "#     cv2.imshow(\"complete\",img1)\n",
    "#     if (cv2.waitKey(10) & 0xFF == ord('q')):\n",
    "#         break\n",
    "    \n",
    "    if frame_counter > 65:\n",
    "        break\n",
    "    \n",
    "\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
